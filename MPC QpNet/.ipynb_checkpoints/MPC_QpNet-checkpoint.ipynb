{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OptNet/qpth Example Notebook\n",
    "\n",
    "*By [Brandon Amos](https://bamos.github.io) and [J. Zico Kolter](http://zicokolter.com/).*\n",
    "\n",
    "---\n",
    "\n",
    "This notebook is released along with our paper\n",
    "[OptNet: Differentiable Optimization as a Layer in Neural Networks](https://arxiv.org/abs/1703.00443).\n",
    "\n",
    "This notebook shows a minimal example of constructing an\n",
    "OptNet layer in PyTorch with our [qpth library](https://github.com/locuslab/qpth).\n",
    "See [our qpth documentation page](https://locuslab.github.io/qpth/)\n",
    "for more details.\n",
    "The experiments for our paper that use this library are in\n",
    "[this repo](https://github.com/locuslab/optnet).\n",
    "\n",
    "\n",
    "## Setup and Dependencies\n",
    "\n",
    "+ Python/numpy/[PyTorch](https://pytorch.org)\n",
    "+ [qpth](https://github.com/locuslab/qpth):\n",
    "  *Our fast QP solver for PyTorch released in conjunction with this paper.*\n",
    "+ [bamos/block](https://github.com/bamos/block):\n",
    "  *Our intelligent block matrix library for numpy, PyTorch, and beyond.*\n",
    "+ Optional: [bamos/setGPU](https://github.com/bamos/setGPU):\n",
    "  A small library to set `CUDA_VISIBLE_DEVICES` on multi-GPU systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "import torch\n",
    "from torch.autograd import Function, Variable\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from instructor import Instructor\n",
    "from qpth.qp import QPFunction\n",
    "\n",
    "\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model\n",
    "\n",
    "+ We'll be using a network architecture that looks like:\n",
    "\n",
    "```\n",
    "FC-ReLU-(BN)-FC-ReLU-(BN)-QP-softmax\n",
    "```\n",
    "\n",
    "where the QP OptNet layer learns the coefficients `Q`, `q`, `G`,\n",
    "`h`, `A`, `b` for a QP with inequality constraints and equality \n",
    "constraints:\n",
    "\n",
    "```\n",
    "z_{i+1} = argmin_z 1/2*z^T*Q*z + p^T*z\n",
    "              subject to G*z <= h\n",
    "                         A*z = b\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from qpth.qp import QPFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QpNet(nn.Module):\n",
    "    \"\"\"Builds the strucre of the QPNet.\n",
    "    \n",
    "    The struture is FC-ReLU-(BN)-FC-ReLU-(BN)-QP-FC.\n",
    "    QP means the optimization problem layer over`nz` variables, \n",
    "    having `nineq` inequality constraints and `neq` equality \n",
    "    constraints.\n",
    "    The optimization problem is of the form\n",
    "        \\hat z =   argmin_z 1/2*z^T*Q*z + p^T*z\n",
    "                subject to G*z <= h\n",
    "                           A*z = b\n",
    "    where Q \\in S^{nz,nz},\n",
    "        S^{nz,nz} is the set of all positive semi-definite matrices,\n",
    "        p \\in R^{nz}\n",
    "        G \\in R^{nineq,nz}\n",
    "        h \\in R^{nineq}\n",
    "        A \\in R^{neq,nz}\n",
    "        b \\in R^{neq}\n",
    "        This layer has Q = L*L^T+ϵ*I where L is a lower-triangular matrix,\n",
    "        and h = G*z0 + s0, b = A*z0 for some learnable z0 and s0,  \n",
    "        to ensure the problem is always feasible.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_input, num_output, num_hidden, bn, num_u=5, eps=1e-4):\n",
    "\n",
    "        \"\"\"Initiates OptNet.\"\"\"\n",
    "        super().__init__()\n",
    "        self.num_input = num_input\n",
    "        self.num_output = num_output\n",
    "        self.num_hidden = num_hidden\n",
    "        self.bn = bn\n",
    "        self.num_u = num_u\n",
    "        self.eps = eps\n",
    "        \n",
    "        self.N = int(self.num_u/self.num_output)  # get the number of the finite steps in MPC\n",
    "        self.num_ineq = num_u + num_input*(self.N-1)\n",
    "        \n",
    "        # normal BN/FC layers.\n",
    "        if bn:\n",
    "            self.bn1 = nn.BatchNorm1d(num_hidden)\n",
    "            self.bn2 = nn.BatchNorm1d(num_u)\n",
    "\n",
    "        self.fc1 = nn.Linear(num_input, num_hidden)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_u)\n",
    "        self.fc3 = nn.Linear(num_u, num_output)\n",
    "\n",
    "        # builds baisc tensors for QP parameters\n",
    "        if torch.cuda.is_available():\n",
    "            self.Variable = lambda *args, **kwargs: \\\n",
    "            torch.autograd.Variable(*args, **kwargs).cuda()\n",
    "            self.Parameter = lambda *args, **kwargs: \\\n",
    "            torch.nn.parameter.Parameter(*args, **kwargs).cuda()\n",
    "        else:\n",
    "            self.Variable = lambda *args, **kwargs: \\\n",
    "            torch.autograd.Variable(*args, **kwargs)\n",
    "            self.Parameter = lambda *args, **kwargs: \\\n",
    "            torch.nn.parameter.Parameter(*args, **kwargs)\n",
    "        self.M = self.Variable(torch.tril(torch.ones(num_input, num_input)))\n",
    "        self.L = self.Parameter(torch.tril(torch.rand(num_input, num_input)))\n",
    "        self.L.retain_grad()\n",
    "        self.M_P = self.Variable(torch.tril(torch.ones(num_input, num_input)))\n",
    "        self.L_P = self.Parameter(torch.tril(torch.rand(num_input, num_input)))\n",
    "        self.L_P.retain_grad()\n",
    "        self.M_R = self.Variable(torch.tril(torch.ones(num_output, num_output)))\n",
    "        self.L_R = self.Parameter(torch.tril(torch.rand(num_output, num_output)))\n",
    "        self.L_R.retain_grad()\n",
    "        self.I = self.Variable(torch.eye(num_input))\n",
    "        self.I_R = self.Variable(torch.eye(num_output))\n",
    "        self.A = self.Parameter(torch.Tensor(num_input,num_input).uniform_(-1,1))\n",
    "        self.A.retain_grad()\n",
    "        self.B = self.Parameter(torch.Tensor(num_input,num_output).uniform_(-1,1))\n",
    "        self.B.retain_grad()\n",
    "        self.u0 = self.Parameter(torch.zeros(num_u))\n",
    "        self.u0.retain_grad()\n",
    "        self.s0 = self.Parameter(torch.ones(self.num_ineq))\n",
    "        self.s0.retain_grad()\n",
    "        self.B_hat = self.build_B_block()\n",
    "        \n",
    "        # set up the QP parameters Q=L*L^T+ϵ*I, h = G*u_0+s_0\n",
    "        L = self.M*self.L\n",
    "        Q = L.mm(L.t()) + self.eps*self.I\n",
    "        L_P = self.M_P*self.L_P\n",
    "        P = L_P.mm(L_P.t()) + self.eps*self.I\n",
    "        L_R = self.M_R*self.L_R\n",
    "        R = L_R.mm(L_R.t()) + self.eps*self.I_R\n",
    "        self.Q_hat = self.build_Q_block(Q, P, R)\n",
    "        \n",
    "        self.G = self.build_G_block()\n",
    "        self.h = self.G.mv(self.u0)+self.s0\n",
    "        \n",
    "        \n",
    "        weight = torch.zeros(num_u)\n",
    "        weight[0] = 1.0\n",
    "        self.weight = self.Variable(weight)\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Builds the forward strucre of the QPNet.\n",
    "        Sequence: FC-ReLU-(BN)-FC-ReLU-(BN)-QP-Softmax.\n",
    "        \"\"\"\n",
    "        nBatch = x.size(0)\n",
    "        \n",
    "        # normal FC network.\n",
    "        x = x.view(nBatch, -1)\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        if self.bn:  # if applies a batch normalization \n",
    "            x = self.bn1(x)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        if self.bn:\n",
    "            x = self.bn2(x)\n",
    "        \n",
    "        # gets the solution of the basic optimization problem\n",
    "        e = Variable(torch.Tensor())\n",
    "        x = QPFunction(verbose=-1)(self.Q_hat, x, self.G, self.h, e, e)  \n",
    "        # shows solver warning if verbose >= 0\n",
    "\n",
    "        return (x.mv(self.weight))  # only return the fisrt action\n",
    "    \n",
    "    def build_B_block(self):\n",
    "        \"\"\"In MPC, express x vector in u vector and compute the new big B_hat matrix\n",
    "        [B 0 0 ...\n",
    "        [AB B 0\n",
    "        ...\n",
    "        \"\"\"\n",
    "\n",
    "        N = self.N  # number of MPC steps\n",
    "        row_list = []  # reocrd the every row in B_hat\n",
    "        \n",
    "        first_block = self.B\n",
    "        zero = self.Variable(torch.zeros(self.num_input, self.num_output*(N-1)))\n",
    "        row= torch.cat([first_block, zero],1)\n",
    "        row_list.append(row)\n",
    "        \n",
    "        for i in range(1, N-1):\n",
    "            first_block = self.A.mm(first_block)\n",
    "            row = torch.cat([first_block, row[:,:self.num_output*(N-1)]],1)\n",
    "            row_list.append(row)  \n",
    "            \n",
    "        return torch.cat(row_list,0)\n",
    "        \n",
    "        \n",
    "    def build_Qdiagnol_block(self, Q, P):\n",
    "        \"\"\" (num_imput*(N-1)) x (num_imput*(N-1))\n",
    "        The last block is P for x(N)\"\"\"\n",
    "        \n",
    "        N = self.N-1  # number of MPC steps\n",
    "        num_input = self.num_input\n",
    "        \n",
    "        row_list = []  # reocrd the every row in B_hat\n",
    "        zero = self.Variable(torch.zeros(num_input, num_input*(N-1)))\n",
    "        row_long = torch.cat([zero, Q, zero],1)  # [0 0 ... Q 0 0 ...]\n",
    "        for i in range(N, 1, -1):\n",
    "            row_list.append(row_long[:, (i-1)*num_input : (i+N-1)*num_input])\n",
    "            \n",
    "        row = torch.cat([zero, P],1)  # last line by [0 P]\n",
    "        row_list.append(row)\n",
    "        \n",
    "        return torch.cat(row_list,0)\n",
    "    \n",
    "    def build_Rdiagnol_block(self, R):\n",
    "        \"\"\"\n",
    "        [R 0 0 ...\n",
    "        [0 R 0\n",
    "        ...\n",
    "        \"\"\"\n",
    "        N = self.N  # number of MPC steps\n",
    "        num_output = self.num_output\n",
    "        \n",
    "        row_list = []  # reocrd the every row in B_hat\n",
    "        zero = self.Variable(torch.zeros(num_output, num_output*(N-1)))\n",
    "        \n",
    "        row_long = torch.cat([zero, R, zero],1)  # [0 0 ... Q 0 0 ...]\n",
    "        \n",
    "        for i in range(N, 0, -1):\n",
    "            row_list.append(row_long[:, (i-1)*num_output : (i+N-1)*num_output])\n",
    "        return torch.cat(row_list,0)\n",
    "        \n",
    "    def build_Q_block(self, Q, P, R):\n",
    "        \"\"\"Build the Q_hat matrix so that MPC is tranfered into basic optimization problem\n",
    "        Q_hat = B_hat^T * diag(Q) * B_hat + diag(R)\n",
    "        \"\"\"\n",
    "        \n",
    "        Q_diag = self.build_Qdiagnol_block(Q,P)\n",
    "        R_diag = self.build_Rdiagnol_block(R)\n",
    "        Q_hat = self.B_hat.t().mm(Q_diag.mm(self.B_hat)) + R_diag\n",
    "        return Q_hat \n",
    "        \n",
    "        \n",
    "    def build_G_block(self):\n",
    "        \"\"\"Build the G matrix so that MPC is tranfered into basic optimization problem\n",
    "        G = [eye(num_u)]\n",
    "            [   B_hat  ]\n",
    "        \"\"\"\n",
    "        \n",
    "        eye = self.Variable(torch.eye(self.num_u))\n",
    "        G = torch.cat((eye, self.B_hat), 0)\n",
    "        print(self.B_hat)\n",
    "        print(G.size())\n",
    "        return G\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2668,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.6508,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.6543, -0.2668,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.1552, -0.6508,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.2677,  0.6543, -0.2668,  0.0000,  0.0000],\n",
      "        [-0.5348, -0.1552, -0.6508,  0.0000,  0.0000],\n",
      "        [ 0.5663, -0.2677,  0.6543, -0.2668,  0.0000],\n",
      "        [-0.0939, -0.5348, -0.1552, -0.6508,  0.0000]], device='cuda:0',\n",
      "       grad_fn=<CatBackward>)\n",
      "torch.Size([13, 5])\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model.\n",
    "dim_inp = x0.shape[1]\n",
    "dim_out = 1\n",
    "num_hid= 10\n",
    "model = OptNet(dim_inp, dim_out, num_hid, bn=True)\n",
    "loss_fun = torch.nn.MSELoss()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Initialize the optimizer.\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "losses_train = []\n",
    "losses_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(5, 0,-1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([1.]) None\n",
      "tensor([1.]) None\n"
     ]
    }
   ],
   "source": [
    "a = Parameter(torch.tensor([1.]))\n",
    "a.retain_grad()\n",
    "print(a.requires_grad)\n",
    "b = Variable(torch.ones(1))\n",
    "\n",
    "c = a+b\n",
    "c.backward()\n",
    "print(a.grad, b.grad)\n",
    "a = torch.tensor([1.])\n",
    "a.requires_grad = True\n",
    "b = torch.tensor([1.])\n",
    "d = a+b\n",
    "d.backward()\n",
    "print(a.grad, b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ex(nn.Module):\n",
    "    def __init__(self):\n",
    "        if torch.cuda.is_available():\n",
    "            Variable = lambda *args, **kwargs: torch.autograd.Variable(*args, **kwargs).cuda()\n",
    "            self.Parameter = lambda *args, **kwargs: torch.nn.parameter.Parameter(*args, **kwargs).cuda() \n",
    "model = ex()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    Variable = lambda *args, **kwargs: torch.autograd.Variable(*args, **kwargs).cuda()\n",
    "    Parameter = lambda *args, **kwargs: torch.nn.parameter.Parameter(*args, **kwargs).cuda() \n",
    "a = Variable(torch.eye(2))\n",
    "b = Parameter(torch.Tensor(2,2).uniform_(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<CatBackward object at 0x7fbabd15c160>\n"
     ]
    }
   ],
   "source": [
    "print(torch.cat((a,b),0).grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "a = Variable(torch.eye(2))\n",
    "b = Variable(torch.Tensor(2,2).uniform_(-1,1))\n",
    "print(torch.cat((a,b),0).grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network\n",
    "\n",
    "+ Create random data for a regression task and then optimize the parameters with Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x0: (81, 2)  |shape of u: (81, 5)\n"
     ]
    }
   ],
   "source": [
    "# load data from .mat file\n",
    "mat = io.loadmat('./1002.mat')\n",
    "x0 = np.transpose(mat['x'])\n",
    "u = np.transpose(mat['u'])\n",
    "print(\"shape of x0:\",x0.shape,\" |shape of u:\",u.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# build input and output in tensor type\n",
    "x = Variable(torch.from_numpy(x0).float(), requires_grad=False)\n",
    "y = Variable((torch.from_numpy(u[:,0])).float(), requires_grad=False)\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 64  |test size: 17\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into train and test\n",
    "dataset = torch.utils.data.TensorDataset(x,y)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "print(\"train size:\",train_size,\" |test size:\",test_size)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# shuffle the data, build dataset batches\n",
    "batch_size = 10\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.0000, -1.5000], device='cuda:0'), tensor(1., device='cuda:0'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9356,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.6236,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.3777,  0.9356,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.6817,  0.6236,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.3009,  0.3777,  0.9356,  0.0000,  0.0000],\n",
      "        [-0.5824, -0.6817,  0.6236,  0.0000,  0.0000],\n",
      "        [ 0.2459,  0.3009,  0.3777,  0.9356,  0.0000],\n",
      "        [-0.4769, -0.5824, -0.6817,  0.6236,  0.0000]], device='cuda:0',\n",
      "       grad_fn=<CatBackward>)\n",
      "torch.Size([13, 5])\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model.\n",
    "dim_inp = x0.shape[1]\n",
    "dim_out = 1\n",
    "num_hid= 10\n",
    "model = QpNet(dim_inp, dim_out, num_hid, bn=True)\n",
    "loss_fun = torch.nn.MSELoss()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Initialize the optimizer.\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "losses_train = []\n",
    "losses_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Instructor():\n",
    "    \"\"\" build functions for model training, evaluation, saving, loading\n",
    "     \n",
    "    evaluate(self, loader): elvauate the loss from loader data \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,model, optimizer, criterion):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        \n",
    "    def train(self, loader, epoch):\n",
    "        \"\"\"Trains the model for one epoch.\n",
    "        Inputs the epcoh number for print information\"\"\"\n",
    "        losses = 0.0\n",
    "        run_loss = 0.0\n",
    "        self.model.train()\n",
    "        for t, (inp, out) in enumerate(loader):\n",
    "            self.optimizer.zero_grad()\n",
    "            out_pre = self.model(inp)\n",
    "            loss = self.criterion(out_pre, out)\n",
    "            run_loss += loss.data\n",
    "            losses += loss.data\n",
    "            if (t+1) % 100 == 0:\n",
    "                print('[epoch: %d, %5d] training loss: %.3f' %\n",
    "                      (epoch + 1, t + 1, run_loss / 100))\n",
    "                run_loss = 0.0\n",
    "            \n",
    "            loss.backward(retain_graph=True)\n",
    "            self.optimizer.step()        \n",
    "        return losses/(t+1)\n",
    "\n",
    "    \n",
    "    def evaluate(self, loader):\n",
    "\n",
    "        losses = 0\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for t, (inp, out) in enumerate(loader):\n",
    "                out_pre = self.model(inp)\n",
    "                loss = self.criterion(out_pre, out)\n",
    "                losses += loss.data\n",
    "#         print('input', inp)\n",
    "#         print('output_pre', out_pre)\n",
    "#         print(out)\n",
    "        return losses/(t+1)\n",
    "    \n",
    "    def save(self,state,dir):\n",
    "        \"\"\" Saves the model in location 'dir'.\n",
    "        example:\n",
    "        state = {'net':model.state_dict(), 'optimizer':optimizer.state_dict(), 'epoch':epoch}\n",
    "        dir = './model_trained/model_name'\n",
    "        \"\"\"\n",
    "        if not os.path.isdir('model_trained'): #save model in a file \"model_trainded\"\n",
    "            os.mkdir('model_trained')\n",
    "        torch.save(state, dir)\n",
    "        print('--- Save last model state')\n",
    "\n",
    "    def load(self,dir):\n",
    "        \"\"\" Loads the model in location 'dir', including net parameter, optimer, epoch number.\n",
    "        Returns the next epoch number\n",
    "        \"\"\"\n",
    "        if not os.path.isdir('model_trained'): #find the file for model saving and loading\n",
    "            os.mkdir('model_trained')\n",
    "        checkpoint = torch.load(dir)\n",
    "        self.model.load_state_dict(checkpoint['net'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        print('--- Load last model state')\n",
    "        print('start epoch:',start_epoch)\n",
    "        return start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1] training loss: 0.138, testing loss: 0.246\n",
      "[epoch: 2] training loss: 0.172, testing loss: 0.222\n",
      "[epoch: 3] training loss: 0.133, testing loss: 0.150\n",
      "[epoch: 4] training loss: 0.179, testing loss: 0.140\n",
      "[epoch: 5] training loss: 0.149, testing loss: 0.128\n",
      "[epoch: 6] training loss: 0.086, testing loss: 0.105\n",
      "[epoch: 7] training loss: 0.145, testing loss: 0.143\n",
      "[epoch: 8] training loss: 0.200, testing loss: 0.164\n",
      "[epoch: 9] training loss: 0.189, testing loss: 0.107\n",
      "[epoch: 10] training loss: 0.088, testing loss: 0.112\n",
      "[epoch: 11] training loss: 0.072, testing loss: 0.131\n",
      "[epoch: 12] training loss: 0.143, testing loss: 0.114\n",
      "[epoch: 13] training loss: 0.315, testing loss: 0.118\n",
      "[epoch: 14] training loss: 0.116, testing loss: 0.081\n",
      "[epoch: 15] training loss: 0.155, testing loss: 0.077\n",
      "[epoch: 16] training loss: 0.127, testing loss: 0.062\n",
      "[epoch: 17] training loss: 0.186, testing loss: 0.076\n",
      "[epoch: 18] training loss: 0.173, testing loss: 0.053\n",
      "[epoch: 19] training loss: 0.087, testing loss: 0.056\n",
      "[epoch: 20] training loss: 0.045, testing loss: 0.059\n",
      "[epoch: 21] training loss: 0.116, testing loss: 0.059\n",
      "[epoch: 22] training loss: 0.128, testing loss: 0.061\n",
      "[epoch: 23] training loss: 0.069, testing loss: 0.071\n",
      "[epoch: 24] training loss: 0.194, testing loss: 0.056\n",
      "[epoch: 25] training loss: 0.320, testing loss: 0.028\n",
      "[epoch: 26] training loss: 0.133, testing loss: 0.047\n",
      "[epoch: 27] training loss: 0.227, testing loss: 0.043\n",
      "[epoch: 28] training loss: 0.061, testing loss: 0.055\n",
      "[epoch: 29] training loss: 0.079, testing loss: 0.056\n",
      "[epoch: 30] training loss: 0.130, testing loss: 0.050\n"
     ]
    }
   ],
   "source": [
    "#from instructor import Instructor\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "instructor = Instructor(model, optimizer, loss_fun)\n",
    "\n",
    "# train the data\n",
    "for epoch in range(30):\n",
    "    loss_train = instructor.train(train_loader,epoch)\n",
    "    loss_test = instructor.evaluate(test_loader)\n",
    "    losses_train.append(loss_train)\n",
    "    losses_test.append(loss_test)\n",
    "    print('[epoch: %d] training loss: %.3f, testing loss: %.3f' %\n",
    "                      (epoch + 1, loss_train, loss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [ 0.9356,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.6236,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.3777,  0.9356,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.6817,  0.6236,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.3009,  0.3777,  0.9356,  0.0000,  0.0000],\n",
       "        [-0.5824, -0.6817,  0.6236,  0.0000,  0.0000],\n",
       "        [ 0.2459,  0.3009,  0.3777,  0.9356,  0.0000],\n",
       "        [-0.4769, -0.5824, -0.6817,  0.6236,  0.0000]], device='cuda:0',\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/season/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:84: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/season/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.764\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-685cd8c2e9aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m# Forward pass: compute predicted y by passing x to the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mout_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Compute and print loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-3f58f8b50739>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQPFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;31m# shows solver warning if verbose >= 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/qpth/qp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, Q_, p_, G_, h_, A_, b_)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 zhats, ctx.nus, ctx.lams, ctx.slacks = pdipm_b.forward(\n\u001b[1;32m     95\u001b[0m                     \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ_LU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS_LU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                     eps, verbose, notImprovedLim, maxIter)\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mQPSolvers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCVXPY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/qpth/solvers/pdipm/batch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(Q, p, G, h, A, b, Q_LU, S_LU, R, eps, verbose, notImprovedLim, maxIter, solver)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;31m# compute centering directions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         alpha = torch.min(torch.min(get_step(z, dz_aff),\n\u001b[0m\u001b[1;32m    160\u001b[0m                                     get_step(s, ds_aff)),\n\u001b[1;32m    161\u001b[0m                           torch.ones(nBatch).type_as(Q))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/qpth/solvers/pdipm/batch.py\u001b[0m in \u001b[0;36mget_step\u001b[0;34m(v, dv)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdv\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    run_loss = 0.0\n",
    "    for t, (inp, out) in enumerate(train_loader):\n",
    "        # Forward pass: compute predicted y by passing x to the model.\n",
    "        out_pred = model(inp)\n",
    "\n",
    "        # Compute and print loss.\n",
    "        loss = loss_fun(out_pred, out)\n",
    "        run_loss = run_loss + loss.data\n",
    "        if (t+1) % 100 == 0:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, t + 1, run_loss / 100))\n",
    "            run_loss = 0.0\n",
    "            losses.append(loss.data)\n",
    "            \n",
    "        # Before the backward pass, use the optimizer object to zero all of the\n",
    "        # gradients for the variables it will update (which are the learnable weights\n",
    "        # of the model)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model\n",
    "        # parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its\n",
    "        # parameters\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(0,10)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.649606310389936)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylim(ymin=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.70174154117703436)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEJCAYAAAByupuRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a886902e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylim(ymin=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1610, device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random data\n",
    "nBatch, nFeatures, nHidden, nz = 16, 20, 20, 2\n",
    "x = Variable(torch.randn(nBatch, nFeatures), requires_grad=False)\n",
    "y = Variable((torch.rand(nBatch) < 0.5).long(), requires_grad=False)\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random data\n",
    "num_dataset, input_dim, output_dim, nz = 16, 5, 3, 2\n",
    "x = Variable(torch.randn(num_dataset, input_dim), requires_grad=False)\n",
    "y = Variable((torch.rand(num_dataset, output_dim)), requires_grad=False)\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "trainset = torch.utils.data.TensorDataset(x, y)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True)\n",
    "for step,(x_step, y_step) in enumerate(trainloader):\n",
    "    print(y_step)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptNet(nn.Module):\n",
    "    \"\"\"Builds the strucre of the QPNet.\n",
    "    \n",
    "    The struture is FC-ReLU-(BN)-FC-ReLU-(BN)-QP-u[0].\n",
    "    QP means the optimization problem layer over`nz` variables, \n",
    "    having `nineq` inequality constraints and `neq` equality \n",
    "    constraints.\n",
    "    The optimization problem is of the form\n",
    "        \\hat z =   argmin_z 1/2*z^T*Q*z + p^T*z\n",
    "                subject to G*z <= h\n",
    "                           A*z = b\n",
    "    where Q \\in S^{nz,nz},\n",
    "        S^{nz,nz} is the set of all positive semi-definite matrices,\n",
    "        p \\in R^{nz}\n",
    "        G \\in R^{nineq,nz}\n",
    "        h \\in R^{nineq}\n",
    "        A \\in R^{neq,nz}\n",
    "        b \\in R^{neq}\n",
    "        This layer has Q = L*L^T+ϵ*I where L is a lower-triangular matrix,\n",
    "        and h = G*z0 + s0, b = A*z0 for some learnable z0 and s0,  \n",
    "        to ensure the problem is always feasible.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dim_inp, dim_out, num_hid, bn, nz=5, nineq=20, neq=10, eps=1e-4):\n",
    "        \"\"\"Inits OptNet.\"\"\"\n",
    "        super().__init__()\n",
    "        self.dim_inp = dim_inp\n",
    "        self.dim_out = dim_out\n",
    "        self.num_hid = num_hid\n",
    "        self.bn = bn\n",
    "        self.nz = nz\n",
    "        self.nineq = nineq\n",
    "        self.neq = neq\n",
    "        self.eps = eps\n",
    "\n",
    "        # Normal BN/FC layers.\n",
    "        if bn:\n",
    "            self.bn1 = nn.BatchNorm1d(num_hid)\n",
    "            self.bn2 = nn.BatchNorm1d(nz)\n",
    "\n",
    "        self.fc1 = nn.Linear(dim_inp, num_hid)\n",
    "        self.fc2 = nn.Linear(num_hid, nz)\n",
    "        self.fc3 = nn.Linear(nz, dim_out)\n",
    "\n",
    "        # QP params.\n",
    "        self.M = Variable(torch.tril(torch.ones(nz, nz)))\n",
    "        self.L = Parameter(torch.tril(torch.rand(nz, nz)))\n",
    "        self.I = Variable(torch.eye(self.nz))\n",
    "        self.G = Parameter(torch.Tensor(nineq,nz).uniform_(-1,1))\n",
    "        self.A = Parameter(torch.Tensor(neq,nz).uniform_(-1,1))\n",
    "        self.z0 = Parameter(torch.zeros(nz))\n",
    "        self.s0 = Parameter(torch.ones(nineq))\n",
    "        \n",
    "        weight = torch.zeros(nz)\n",
    "        weight[0] = 1.0\n",
    "        self.weight = Variable(weight)\n",
    "        \n",
    "        if torch.cuda.is_available():  # if able to use GPU\n",
    "            self.M = self.M.cuda()\n",
    "            self.L = Parameter(torch.tril(torch.rand(nz, nz)).cuda())\n",
    "            self.I = Variable(torch.eye(self.nz).cuda())\n",
    "            self.G = Parameter(torch.Tensor(nineq,nz).uniform_(-1,1).cuda())\n",
    "            self.A = Parameter(torch.Tensor(neq,nz).uniform_(-1,1).cuda())\n",
    "            self.z0 = Parameter(torch.zeros(nz).cuda())\n",
    "            self.s0 = Parameter(torch.ones(nineq).cuda())\n",
    "            self.weight = self.weight.cuda()\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Builds the forward strucre of the QPNet.\n",
    "        Sequence: FC-ReLU-(BN)-FC-ReLU-(BN)-QP-u[0].\n",
    "        \"\"\"\n",
    "        nBatch = x.size(0)\n",
    "        \n",
    "        # Normal FC network.\n",
    "        x = x.view(nBatch, -1)\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        if self.bn:  # if applies a batch normalization \n",
    "            x = self.bn1(x)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        if self.bn:\n",
    "            x = self.bn2(x)\n",
    "\n",
    "        # Set up the qp parameters Q=L*L^T+ϵ*I, h = G*z_0+s_0, b = A*z0.\n",
    "        L = self.M*self.L\n",
    "        Q = L.mm(L.t()) + self.eps*self.I\n",
    "        h = self.G.mv(self.z0)+self.s0\n",
    "        b = self.A.mv(self.z0)\n",
    "        x = QPFunction(verbose=-1)(Q, x, self.G, h, self.A, b)\n",
    "        # shows solver warning if verbose >= 0\n",
    "\n",
    "        return (x.mv(self.weight))  # only return the fisrt action"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
