{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import torch\n",
    "from cvxpylayers.torch import CvxpyLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n, m = 2, 3\n",
    "x = cp.Variable(n)\n",
    "A = cp.Parameter((m, n))\n",
    "b = cp.Parameter(m)\n",
    "constraints = [x >= 0]\n",
    "objective = cp.Minimize(0.5 * cp.pnorm(A @ x - b, p=1))\n",
    "problem = cp.Problem(objective, constraints)\n",
    "assert problem.is_dpp()\n",
    "\n",
    "cvxpylayer = CvxpyLayer(problem, parameters=[A, b], variables=[x])\n",
    "A_tch = torch.randn(m, n, requires_grad=True)\n",
    "b_tch = torch.randn(m, requires_grad=True)\n",
    "\n",
    "# solve the problem\n",
    "solution, = cvxpylayer(A_tch, b_tch)\n",
    "\n",
    "# compute the gradient of the sum of the solution with respect to A, b\n",
    "solution.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.8328e-12, -3.0530e-12],\n",
       "        [-1.1125e+00, -1.2586e+00],\n",
       "        [-9.3174e-01, -1.0541e+00]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_tch.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.8214e-12, 1.1175e+00, 9.3591e-01])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_tch.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1481, -1.1520],\n",
       "        [ 1.1613, -0.1775],\n",
       "        [-0.3182,  1.2804]], requires_grad=True)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_tch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4024, 0.9563, 1.1253], requires_grad=True)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_tch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_from_taylor: [tensor(0.), tensor(1.1175), tensor(0.9358)]\n",
      "gradient_from_cvx: tensor([2.8214e-12, 1.1175e+00, 9.3591e-01])\n"
     ]
    }
   ],
   "source": [
    "cnst = 0.001\n",
    "gradient = []\n",
    "for i in range(m):\n",
    "    add = torch.zeros(m)\n",
    "    add[i]=cnst\n",
    "    b_more = b_tch + add\n",
    "    # print(\"b_tch:\",b_tch,\"\\nb_more:\", b_more)\n",
    "    solution_more, = cvxpylayer(A_tch, b_more)\n",
    "    # e.g.:f(b_tch+[0.001;0;0])=f(b_tch)+grad^T*[0.001;0;0]\n",
    "    gradient.append((solution_more.sum()-solution.sum()).data/cnst)\n",
    "print(\"gradient_from_taylor:\",gradient)\n",
    "print(\"gradient_from_cvx:\",b_tch.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_from_taylor: tensor([[ 0.0000,  0.0000],\n",
      "        [-1.1206, -1.2636],\n",
      "        [-0.9298, -1.0729]])\n",
      "gradient_from_cvx: tensor([[-2.8328e-12, -3.0530e-12],\n",
      "        [-1.1125e+00, -1.2586e+00],\n",
      "        [-9.3174e-01, -1.0541e+00]])\n"
     ]
    }
   ],
   "source": [
    "gradient = torch.zeros(m,n)\n",
    "cnst = 0.00001\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        add = torch.zeros(m,n)\n",
    "        add[i,j]=cnst\n",
    "        A_more = A_tch + add\n",
    "        # print(\"A_tch:\",A_tch,\"\\nb_more:\", A_more, \"\\n\")\n",
    "        solution_more, = cvxpylayer(A_more, b_tch)\n",
    "        # e.g.:f(b_tch+[0.001;0;0])=f(b_tch)+grad^T*[0.001;0;0]\n",
    "        gradient[i,j]=((solution_more.sum()-solution.sum()).data/cnst)\n",
    "print(\"gradient_from_taylor:\",gradient)\n",
    "print(\"gradient_from_cvx:\",A_tch.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when gradients are very small(e.g.:^-05, the values are different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QP example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "\n",
    "def QP_layer(nz, nineq, neq):\n",
    "    \"\"\"Builds the QP layer.\n",
    "\n",
    "    The optimization problem is of the form\n",
    "        \\hat z =   argmin_z z^T*Q*z + p^T*z\n",
    "                subject to G*z <= h\n",
    "    where Q \\in S^{nz,nz},\n",
    "        S^{nz,nz} is the set of all positive semi-definite matrices,\n",
    "        p \\in R^{nz}\n",
    "        G \\in R^{nineq,nz}\n",
    "        h \\in R^{nineq}\n",
    "    \n",
    "    Take the matrix square-root of Q：mentioned in paper P19\n",
    "    (Differentiable Convex Optimization Layers).\n",
    "    \"\"\"\n",
    "    Q_sqrt = cp.Parameter((nz, nz))\n",
    "    p = cp.Parameter(nz)\n",
    "    G = cp.Parameter((nineq, nz))\n",
    "    h = cp.Parameter(nineq)\n",
    "    A = cp.Parameter ((neq,nz))\n",
    "    b = cp.Parameter (neq)\n",
    "    z = cp.Variable(nz)\n",
    "    obj = cp.Minimize(cp.sum_squares(Q_sqrt*z) + p.T@z)\n",
    "    cons = [ A@z == b , G@z <= h ]\n",
    "    prob = cp. Problem(obj, cons)\n",
    "    assert prob.is_dpp()\n",
    "\n",
    "    layer = CvxpyLayer (prob, \n",
    "                        parameters =[Q_sqrt, p, A, b, G, h], \n",
    "                        variables =[ z ])\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 2\n",
    "nineq = 1\n",
    "neq = 1\n",
    "layer = QP_layer(nx, nineq, neq)\n",
    "\n",
    "Q_sqrtval = torch . randn ( nx , nx , requires_grad = True )\n",
    "pval = torch . randn ( nx , requires_grad = True )\n",
    "Gval = torch . randn ( nineq , nx , requires_grad = True )\n",
    "hval = torch . randn ( nineq , requires_grad = True )\n",
    "Aval = torch . randn ( neq , nx , requires_grad = True )\n",
    "bval = torch . randn ( neq , requires_grad = True )\n",
    "\n",
    "# solution\n",
    "z, = layer ( Q_sqrtval , pval  , Aval , bval , Gval , hval )\n",
    "\n",
    "# compute the gradient of the sum of the solution \n",
    "# with respect to parameters\n",
    "z.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_from_taylor: tensor([[-0.0030, -0.0656],\n",
      "        [-0.8106, -0.0685]])\n",
      "gradient_from_cvx: tensor([[-0.0025, -0.0619],\n",
      "        [-0.8098, -0.0691]])\n"
     ]
    }
   ],
   "source": [
    "gradient = torch.zeros(nx,nx)\n",
    "cnst = 0.00001\n",
    "for i in range(nx):\n",
    "    for j in range(nx):\n",
    "        add = torch.zeros(nx,nx)\n",
    "        add[i,j]=cnst\n",
    "        Q_more = Q_sqrtval + add\n",
    "        # print(\"A_tch:\",A_tch,\"\\nb_more:\", A_more, \"\\n\")\n",
    "        z_more, = layer(Q_more, pval, Aval, bval, Gval, hval)\n",
    "        # e.g.:f(b_tch+[0.001;0;0])=f(b_tch)+grad^T*[0.001;0;0]\n",
    "        gradient[i,j]=((z_more.sum()-z.sum()).data/cnst)\n",
    "print(\"gradient_from_taylor:\",gradient)\n",
    "print(\"gradient_from_cvx:\",Q_sqrtval.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QP example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "\n",
    "def QP_layer(nz, nineq, neq):\n",
    "    \"\"\"Builds the QP layer.\n",
    "\n",
    "    The optimization problem is of the form\n",
    "        \\hat z =   argmin_z z^T*Q*z + p^T*z\n",
    "                subject to G*z <= h\n",
    "    where Q \\in S^{nz,nz},\n",
    "        S^{nz,nz} is the set of all positive semi-definite matrices,\n",
    "        p \\in R^{nz}\n",
    "        G \\in R^{nineq,nz}\n",
    "        h \\in R^{nineq}\n",
    "    \n",
    "    Take the matrix square-root of Q：mentioned in paper P19\n",
    "    (Differentiable Convex Optimization Layers).\n",
    "    \"\"\"\n",
    "    Q_sqrt = cp.Parameter((nz, nz))\n",
    "    p = cp.Parameter(nz)\n",
    "    G = cp.Parameter((nineq, nz))\n",
    "    h = cp.Parameter(nineq)\n",
    "    A = cp.Parameter ((neq,nz))\n",
    "    b = cp.Parameter (neq)\n",
    "    z = cp.Variable(nz)\n",
    "    x = cp.Variable(nz)\n",
    "    obj = cp.Minimize(cp.sum_squares(Q_sqrt*z) + p.T@z)\n",
    "    cons = [ A@z == b , G@z <= h, A@x == b ]\n",
    "    prob = cp. Problem(obj, cons)\n",
    "    assert prob.is_dpp()\n",
    "\n",
    "    layer = CvxpyLayer (prob, \n",
    "                        parameters =[Q_sqrt, p, A, b, G, h], \n",
    "                        variables =[ z,x ])\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 2\n",
    "nineq = 1\n",
    "neq = 1\n",
    "layer = QP_layer(nx, nineq, neq)\n",
    "\n",
    "Q_sqrtval = torch . randn ( nx , nx , requires_grad = True )\n",
    "pval = torch . randn ( nx , requires_grad = True )\n",
    "Gval = torch . randn ( nineq , nx , requires_grad = True )\n",
    "hval = torch . randn ( nineq , requires_grad = True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.7655, 17.0133], grad_fn=<_CvxpyLayerFnFnBackward>) tensor([0.5447, 1.9047], grad_fn=<_CvxpyLayerFnFnBackward>)\n"
     ]
    }
   ],
   "source": [
    "Aval = torch . randn ( neq , nx , requires_grad = True )\n",
    "bval = torch . randn ( neq , requires_grad = True )\n",
    "z,x = layer ( Q_sqrtval , pval  , Aval , bval , Gval , hval )\n",
    "print(z,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 13.1131, -24.3364], grad_fn=<_CvxpyLayerFnFnBackward>)\n"
     ]
    }
   ],
   "source": [
    "Aval = torch . zeros ( neq , nx , requires_grad = True )\n",
    "bval = torch . zeros ( neq , requires_grad = True )\n",
    "Y, = layer ( Q_sqrtval , pval  , Aval , bval , Gval , hval )\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# soft MPC in QP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import cvxpy as cp\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "\n",
    "from matrix_square_root import sqrtm\n",
    "\n",
    "def QP_layer(nz, nineq_u, nineq_x):\n",
    "    \"\"\"Builds the QP layer with MPC soft constraints.\n",
    "\n",
    "    The optimization problem is of the form\n",
    "        \\hat z,\\hat e  =   argmin_z z^T*Q*z + p^T*z + e^T*E*e\n",
    "                subject to G1*z <= h1\n",
    "                            G2*z <= h2+e\n",
    "                \n",
    "    where Q \\in S^{nz,nz},\n",
    "        S^{nz,nz} is the set of all positive semi-definite matrices,\n",
    "        p \\in R^{nz}\n",
    "        G1 \\in R^{nineq_u,nz}\n",
    "        h1 \\in R^{nineq_u}\n",
    "        G2 \\in R^{nineq_x,nz}\n",
    "        h2 \\in R^{nineq_x}\n",
    "        E \\in S^{ne,ne}, where ne = nineq_x\n",
    "    \n",
    "    Take the matrix square-root of Q：mentioned in paper P19\n",
    "    (Differentiable Convex Optimization Layers).\n",
    "    \"\"\"\n",
    "    Q_sqrt = cp.Parameter((nz, nz))\n",
    "    p = cp.Parameter(nz)\n",
    "    G1 = cp.Parameter((nineq_u, nz))\n",
    "    h1 = cp.Parameter(nineq_u)\n",
    "    G2 = cp.Parameter((nineq_x, nz))\n",
    "    h2 = cp.Parameter(nineq_x)\n",
    "    E_sqrt = cp.Parameter((nineq_x, nineq_x))\n",
    "    z = cp.Variable(nz)\n",
    "    e = cp.Variable(nineq_x)\n",
    "    obj = cp.Minimize(cp.sum_squares(Q_sqrt*z) + p.T@z +\n",
    "                     cp.sum_squares(E_sqrt*e))\n",
    "    cons = [ G1@z <= h1,G2@z <= h2+e,e>=0 ]\n",
    "    prob = cp. Problem(obj, cons)\n",
    "    assert prob.is_dpp()\n",
    "\n",
    "    layer = CvxpyLayer (prob, \n",
    "                        parameters =[Q_sqrt, p, G1, h1, G2,\n",
    "                                     h2, E_sqrt], \n",
    "                        variables =[ z, e ])\n",
    "    return layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2407, -0.1167], grad_fn=<_CvxpyLayerFnFnBackward>) tensor([0.8969, 1.9070], grad_fn=<_CvxpyLayerFnFnBackward>)\n"
     ]
    }
   ],
   "source": [
    "nx = 2\n",
    "nineq_u = 3\n",
    "nineq_x = 2\n",
    "layer = QP_layer(nx, nineq_u, nineq_x)\n",
    "\n",
    "Q_sqrt = torch . randn ( nx , nx , requires_grad = True )\n",
    "E_sqrt = torch . randn ( nineq_x , nineq_x , requires_grad = True )\n",
    "p = torch . randn ( nx , requires_grad = True )\n",
    "G1 = torch . randn ( nineq_u , nx , requires_grad = True )\n",
    "h1 = torch . randn ( nineq_u , requires_grad = True )\n",
    "G2 = torch . randn ( nineq_x , nx , requires_grad = True )\n",
    "h2 = torch . randn ( nineq_x , requires_grad = True )\n",
    "Y,e, = layer ( Q_sqrt , p  , G1 , h1,G2 , h2, E_sqrt )\n",
    "print(Y,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor([[-2.7230, -1.0178],\n",
    "        [ 1.4908, -0.7412],\n",
    "        [-3.0117,  0.3030]]) tensor([[ 0.5000],\n",
    "        [ 0.4467],\n",
    "        [-0.0851]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
