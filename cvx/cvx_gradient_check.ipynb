{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import torch\n",
    "from cvxpylayers.torch import CvxpyLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n, m = 2, 3\n",
    "x = cp.Variable(n)\n",
    "A = cp.Parameter((m, n))\n",
    "b = cp.Parameter(m)\n",
    "constraints = [x >= 0]\n",
    "objective = cp.Minimize(0.5 * cp.pnorm(A @ x - b, p=1))\n",
    "problem = cp.Problem(objective, constraints)\n",
    "assert problem.is_dpp()\n",
    "\n",
    "cvxpylayer = CvxpyLayer(problem, parameters=[A, b], variables=[x])\n",
    "A_tch = torch.randn(m, n, requires_grad=True)\n",
    "b_tch = torch.randn(m, requires_grad=True)\n",
    "\n",
    "# solve the problem\n",
    "solution, = cvxpylayer(A_tch, b_tch)\n",
    "\n",
    "# compute the gradient of the sum of the solution with respect to A, b\n",
    "solution.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5139e-08,  1.0238e-08],\n",
       "        [ 1.0998e+01,  7.5741e+00],\n",
       "        [-2.1939e+01, -1.5109e+01]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_tch.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.4693e-09, -4.7209e+00,  9.4172e+00])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_tch.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6674, -1.3942],\n",
       "        [ 0.9303, -1.8197],\n",
       "        [ 0.5725, -0.8060]], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_tch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2441, -0.7523,  0.0406], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_tch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_tch: tensor([ 1.2441, -0.7523,  0.0406], requires_grad=True) \n",
      "b_more: tensor([ 1.2451, -0.7523,  0.0406], grad_fn=<AddBackward0>)\n",
      "b_tch: tensor([ 1.2441, -0.7523,  0.0406], requires_grad=True) \n",
      "b_more: tensor([ 1.2441, -0.7513,  0.0406], grad_fn=<AddBackward0>)\n",
      "b_tch: tensor([ 1.2441, -0.7523,  0.0406], requires_grad=True) \n",
      "b_more: tensor([ 1.2441, -0.7523,  0.0416], grad_fn=<AddBackward0>)\n",
      "gradient_from_taylor: [tensor(0.), tensor(-4.7207), tensor(9.4173)]\n",
      "gradient_from_cvx: tensor([-6.4693e-09, -4.7209e+00,  9.4172e+00])\n"
     ]
    }
   ],
   "source": [
    "gradient = []\n",
    "for i in range(m):\n",
    "    add = torch.zeros(m)\n",
    "    add[i]=0.001\n",
    "    b_more = b_tch + add\n",
    "    print(\"b_tch:\",b_tch,\"\\nb_more:\", b_more)\n",
    "    solution_more, = cvxpylayer(A_tch, b_more)\n",
    "    # e.g.:f(b_tch+[0.001;0;0])=f(b_tch)+grad^T*[0.001;0;0]\n",
    "    gradient.append((solution_more.sum()-solution.sum()).data/0.001)\n",
    "print(\"gradient_from_taylor:\",gradient)\n",
    "print(\"gradient_from_cvx:\",b_tch.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QP example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "\n",
    "def QP_layer(nz, nineq):\n",
    "    \"\"\"Builds the QP layer.\n",
    "\n",
    "    The optimization problem is of the form\n",
    "        \\hat z =   argmin_z z^T*Q*z + p^T*z\n",
    "                subject to G*z <= h\n",
    "    where Q \\in S^{nz,nz},\n",
    "        S^{nz,nz} is the set of all positive semi-definite matrices,\n",
    "        p \\in R^{nz}\n",
    "        G \\in R^{nineq,nz}\n",
    "        h \\in R^{nineq}\n",
    "    \n",
    "    Take the matrix square-root of Qï¼šmentioned in paper P19\n",
    "    (Differentiable Convex Optimization Layers).\n",
    "    \"\"\"\n",
    "    Q_sqrt = cp.Parameter((nz, nz))\n",
    "    p = cp.Parameter(nz)\n",
    "    G = cp.Parameter((nineq, nz))\n",
    "    h = cp.Parameter(nineq)\n",
    "    z = cp.Variable(nz)\n",
    "    obj = cp.Minimize(cp.sum_squares(Q_sqrt*z) + p.T@z)\n",
    "    cons = [ G@z <= h ]\n",
    "    prob = cp. Problem(obj, cons)\n",
    "    assert prob.is_dpp()\n",
    "\n",
    "    layer = CvxpyLayer (prob, \n",
    "                        parameters =[Q_sqrt, p, G, h], \n",
    "                        variables =[ z ])\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0968,  1.0110],\n",
      "        [ 0.1041, -0.1462]], grad_fn=<_CvxpyLayerFnFnBackward>)\n"
     ]
    }
   ],
   "source": [
    "nx = 2\n",
    "ncon_ineq = 1\n",
    "layer = QP_layer(nx,ncon_ineq)\n",
    "\n",
    "Q_sqrtval = torch . randn ( 2,nx , nx , requires_grad = True )\n",
    "pval = torch . randn ( 2,nx , requires_grad = True )\n",
    "Gval = torch . randn ( 2,ncon_ineq , nx , requires_grad = True )\n",
    "hval = torch . randn ( 2,ncon_ineq , requires_grad = True )\n",
    "y, = layer ( Q_sqrtval , pval  , Gval , hval )\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gval.ndimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 1, 2])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2)\n",
    "print(x.repeat(4,1).size())\n",
    "\n",
    "x.repeat(4, 2, 1,1).size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
